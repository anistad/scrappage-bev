{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data for BEV program\n",
    "This script prepares the input data from the calculation of the LCA of the Replace and Retire program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run initialize_notebook.ipynb\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for size and number of cars on county level for the cities affected by driving bans "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data from KBA (fz1) on county level from https://www.kba.de/DE/Statistik/Fahrzeuge/Bestand/ZulassungsbezirkeGemeinden/zulassungsbezirke_node.html\n",
    "\n",
    "Use this data and calculate the number of diesel (and potential petrol cars) affected by a driving ban limited to euro 5 or euro 4. Calculate the size distribution in each of these cities afterwards. \n",
    "\n",
    "\n",
    "The list of cities with excedance of the NO2-limits is available from: https://www.umweltbundesamt.de/sites/default/files/medien/2546/dokumente/no2-ueberschreitungen_staedte_stand_18.01.2019.pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the KBA data and create dataframes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/raw data/Replace and Retire/fz1_2019.xlsx\"\n",
    "\n",
    "#Number of cars by powertrain\n",
    "df = pd.read_excel(path, sheet_name = 'Pkw', skiprows = 6, header = 2)\n",
    "#Number of cars by motor size \n",
    "df_size = pd.read_excel(path, sheet_name = 'Kfz_u_Kfz_Anh', skiprows = 8)\n",
    "df_size = df_size[['Statistische Kennziffer und Zulassungsbezirk', 'Hubraum\\nbis \\n1.399 cm続', '1.400\\nbis\\n1.999 cm続', '2.000\\nund\\nmehr cm続','unbe-\\nkannt '    ]].iloc[0:444,:]\n",
    "\n",
    "#List of cities with potential driving bans/exceeding NO2 limits\n",
    "df_cities = pd.read_excel(\"./data/raw data/Replace and Retire/Cities_driving_bans.xlsx\", sheet_name = 'Modified list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe with total number of cars by powertrain in each county\n",
    "df_tot = df[['Statistische Kennziffer und Zulassungsbezirk', 'Insgesamt', 'Benzin',\n",
    "       'Diesel', 'Hybrid \\ninsgesamt',\n",
    "       'darunter Hybrid mit \\nPlug-in', 'Elektro', 'sonstige']].iloc[0:444,:]\n",
    "\n",
    "#Dataframe with total number of petrol cars in each county \n",
    "df_petrol = df[['Statistische Kennziffer und Zulassungsbezirk','Euro 1',\n",
    "       'Euro 2', 'Euro 3', 'Euro 4', 'Euro 5', 'Euro 6', 'darunter\\nEuro 6d',\n",
    "       'darunter\\nEuro 6d-temp', 'sonstige.1',\n",
    "       'schadstoff-\\nreduzierte \\ninsgesamt']].iloc[0:444,:]\n",
    "#df_petrol.set_index('Statistische Kennziffer und Zulassungsbezirk', inplace = True)\n",
    "\n",
    "#Dataframe with total number of diesel cars in each county \n",
    "df_diesel = df[['Statistische Kennziffer und Zulassungsbezirk','Euro 1.1', 'Euro 2.1',\n",
    "       'Euro 3.1', 'Euro 4.1', 'Euro 5.1', 'Euro 6.1', 'darunter\\nEuro 6d.1',\n",
    "       'darunter\\nEuro 6d-temp.1', 'sonstige.2',\n",
    "       'schadstoffred.\\nmit Diesel-\\nantrieb insgesamt' ]].iloc[0:444,:]\n",
    "#set_index here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code to be able to match the list of cities (with NO2 exceedances) in with the cities of the KBA data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = df_cities.iloc[:,0].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "store_list = list()\n",
    "modified_list = list()\n",
    "for row, index in df_tot.iterrows(): \n",
    "    for city in cities:\n",
    "         if city.upper() in str(index[0]):\n",
    "                modified_list.append(str(index[0]))\n",
    "                store_list.append(city)\n",
    "        \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These cities are not found, need to check for consistency \n",
    "missing = (list(set(cities)-set(store_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row, index in df_tot.iterrows(): \n",
    "    for city in missing: \n",
    "        if (city.split()[0]) in str(index[0]): \n",
    "            modified_list.append(str(index[0]))\n",
    "            store_list.append(city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These cities are not found in the data from KBA fz1 (so do not consider them for now): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(list(set(cities)-set(store_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some of the citites are removed from the dataframe as they both are cities and regions\n",
    "modified_list.remove('08125  HEILBRONN                   ')\n",
    "modified_list.remove('09772  AUGSBURG                    ')\n",
    "modified_list.remove('06531  GIESSEN                     ')\n",
    "modified_list.remove('07339  MAINZ-BINGEN                ')\n",
    "modified_list.remove('14729  LEIPZIG                     ')\n",
    "modified_list.remove('07137  MAYEN-KOBLENZ               ')\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of the 59 citites with driving bans found in fz1:\n",
    "-  from the 2019 updated list there are 67 cities \n",
    "-  remove the 4 that is green (NO2 values under limit) so far \n",
    "-  4 cities not found in fz1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out only the cities affected by diesel bans from the dataframes of total cars and calculate the number of cars <= euro 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframes only containing the relevant counties \n",
    "filter1 = df_diesel['Statistische Kennziffer und Zulassungsbezirk'].isin(modified_list)\n",
    "diesel_ban = df_diesel[filter1]\n",
    "petrol_ban = df_petrol[filter1]\n",
    "size_ban = df_size[filter1]\n",
    "\n",
    "#Setting index\n",
    "size_ban.set_index('Statistische Kennziffer und Zulassungsbezirk', inplace = True)\n",
    "diesel_ban.set_index('Statistische Kennziffer und Zulassungsbezirk', inplace = True)\n",
    "petrol_ban.set_index('Statistische Kennziffer und Zulassungsbezirk', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of diesel cars <= euro 5 and <= euro 4 is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sum(diesel_ban.iloc[:,0:5].sum(axis =1)))\n",
    "print(sum(diesel_ban.iloc[:,0:4].sum(axis =1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diesel_ban.iloc[:,0:5].sum(axis = 0).plot.barh(stacked = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some of the cities also petrol cars less than euro 2 or/and euro 1 is considered. \n",
    "Calculate the number of these cars and the share of them compared to diesel cars older or equal to euro 5: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(petrol_ban.iloc[:,0:2].sum(axis =1)))\n",
    "\n",
    "print(sum(petrol_ban.iloc[:,0:2].sum(axis =1))/sum(diesel_ban.iloc[:,0:5].sum(axis =1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need the size distribution in each of the cities with potential driving bans. \n",
    "The differences in size distribution are quite large among the counties: \n",
    "-  lowest share of small vehicles in M端nchen (26 %) and highest in Bochum (43 %) \n",
    "- lowest share of medium vehicles in Oberhausn (44 %) and highest in Bonn (53 %)\n",
    "- lowest share of large vehicles in Wittenberg (10 %) and highest in Stuttgart (23%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_dist = list()\n",
    "for row, index in size_ban.iterrows(): \n",
    "    size_dist.append(index[0:3]/sum(index[0:3]))\n",
    "size_dist = pd.concat(size_dist, axis = 1).T    \n",
    "    #size_ban.set_index('Statistische Kennziffer und Zulassungsbezirk').iloc[:,1:4].sum(axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(zip(size_dist.idxmin(), size_dist.min())))\n",
    "print(list(zip(size_dist.idxmax(), size_dist.max())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataframe with the euro class and size distribution of the old  DIESEL cars. Have to assume the same size distribution across all emission concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "keys_size = list(size_dist.iloc[1,:].index)\n",
    "df_list = list()\n",
    "for row, index in diesel_ban.iloc[:,0:5].iterrows(): \n",
    "    temp = [index*size_dist.iloc[idx,:].values[i] for i in [0,1,2]]\n",
    "    idx+=1\n",
    "    df = pd.concat(temp, axis = 1, keys = keys_size)\n",
    "    df_list.append(df)\n",
    "df_old = pd.concat(df_list, keys = diesel_ban.index)\n",
    "\n",
    "#Dataframe with number of diesel cars per emission concept and size class \n",
    "df_old.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking that the size distribution is the same as before REWRITE\n",
    "index_list = list(df_old.groupby('Statistische Kennziffer und Zulassungsbezirk').sum().index)\n",
    "df_size=pd.DataFrame([df_old.loc[index_list[i]].sum(axis = 0)/sum(df_old.loc[index_list[i]].sum(axis = 0)) for i in np.arange(len(index_list))]).set_index(size_dist.index)\n",
    "\n",
    "#for row, index in df_check.iterrows(): \n",
    " #   print(index)\n",
    "  #  #df_size = df_size[['Statistische Kennziffer und Zulassungsbezirk', 'Hubraum\\nbis \\n1.399 cm続', '1.400\\nbis\\n1.999 cm続', '2.000\\nund\\nmehr cm続','unbe-\\nkannt '    ]].iloc[0:444,:]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program should be limited to less cars than 2 million (ref. program from 2009). Assume that all euro 4 cars will be involved and that the rest of the budget will be dedicated to some euro 5 cars: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Program limited to euro 4 and including some euro 5 for the rest of the budget\n",
    "tot_cars_in_program = 2000000\n",
    "share_euro5 = (tot_cars_in_program-sum(diesel_ban.iloc[:,0:4].sum(axis =1)))/(sum(diesel_ban.iloc[:,0:5].sum(axis =1))-sum(diesel_ban.iloc[:,0:4].sum(axis =1)))\n",
    "for row, index in df_old.iterrows(): \n",
    "    if 'Euro 5.1' in row: \n",
    "        df_old.loc[row] = df_old.loc[row]*share_euro5\n",
    "    #If one \n",
    "#    if 'Euro 4.1' in row: \n",
    "#        df_old.loc[row] = df_old.loc[row]*0\n",
    "        \n",
    "#Checking that the number is still equal to tot_cars_in_program\n",
    "df_old.groupby('Statistische Kennziffer und Zulassungsbezirk').sum()\n",
    "print(sum(df_old.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want to limit the program to only euro 4 cars or euro 3 this code can be used: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for row, index in df_old.iterrows(): \n",
    "#    if 'Euro 5.1' in row: \n",
    "#        df_old.loc[row] = df_old.loc[row]*0\n",
    "#    if 'Euro 4.1' in row: \n",
    "#        df_old.loc[row] = df_old.loc[row]*0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking that the total number of cars from the dataframe diesel_ban equals the sum over all size classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in np.arange(0,len(diesel_ban)): \n",
    "    if (sum(df_old.xs(diesel_ban.index[i], level = 0).sum(axis = 1)) == diesel_ban.iloc[:,0:5].sum(axis =1)[i]):\n",
    "        print(sum(df_old.xs(diesel_ban.index[i], level = 0).sum(axis = 1)) == diesel_ban.iloc[:,0:5].sum(axis =1)[i])\n",
    "    else: \n",
    "        print(diesel_ban.index[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the size and emission concepts in each county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can plot distribution of emission concepts and size for each county like this \n",
    "df_old.xs('08111  STUTTGART,STADT             ', level = 0).plot(kind = 'bar', stacked = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of vehicles by size class\n",
    "ax = df_old.sum(axis = 0, level = 0).plot.barh(stacked = True, figsize = [5,10])\n",
    "ax.set(xlabel = 'number of vehicles', ylabel = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of vehicles by euro class \n",
    "ax = df_old.sum(axis = 1).unstack().plot.barh(stacked = True, figsize = [5,10])\n",
    "ax.set(xlabel = 'number of vehicles', ylabel = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the size distribution of newly bought EV  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the size distribution of the new EVs in the program, data from a report of EVs bought under the current subsidy program is used (available from: https://www.bafa.de/SharedDocs/Downloads/DE/Energie/emob_zwischenbilanz.pdf?__blob=publicationFile&v=43).\n",
    "\n",
    "In addition the larger Teslas are accounted for (model X) (https://www.kba.de/DE/Statistik/Fahrzeuge/Neuzulassungen/MonatlicheNeuzulassungen/2018/2018_node.html, FZ10). \n",
    "The size classes are taken from the auto-umweltliste. \n",
    "\n",
    "As this data is available only for the Germany and not on county level it is assumed that the size distribution of the new EV cars are the same independent of the county (have seen from the data on the current stock that this may vary). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_size_dist = pd.read_excel(\"./data/raw data/Replace and Retire/emob_zwischenbilanz.xlsx\", sheet_name = 'Only EV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translating the EV vehicle sizes from auto-umweltliste etc. \n",
    "size_dict = {1: 'Mini', 2: 'Kleinwagen', 3: 'Untere Mittelklasse', 4: 'Mittelklasse', 5: 'Obere Mittelklasse', 6: 'Luxusklasse', 7: 'Sportswagen',  8: 'Cabriolet', 9: 'SUV', 10: 'Van', 11: 'Van' }\n",
    "df_size_dist.replace({'Size class':size_dict}, inplace = True)\n",
    "df_size_dist.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping the BEVs sold by size classes \n",
    "df_size_dist = df_size_dist[['Size class','Anzahl']].groupby('Size class').sum()\n",
    "df_size_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping into 7 PSI size classes (small, medium, large) \n",
    "df_size_dist = df_size_dist.append(df_size_dist.loc[['Lieferwagen', 'Kastenwagen', 'Pritschenwagen', 'Van']].sum(), \n",
    "                    ignore_index = True).drop([1,3,7,10])\n",
    "df_size_dist.index = ['Cabriolet', 'Kleinwagen', 'Luxusklasse', 'Medium', 'Mini', 'SUV', 'Untere Mittelklasse', 'Van']\n",
    "\n",
    "df_size_dist = df_size_dist.append(df_size_dist.loc[['Cabriolet', 'SUV']].sum(), \n",
    "                    ignore_index = True).drop([0,5])\n",
    "df_size_dist.index = ['Kleinwagen', 'Luxusklasse', 'Medium', 'Mini', 'Untere Mittelklasse', 'Van', 'SUV']\n",
    "\n",
    "#PSI size classes \n",
    "df_size_dist.index = ['Small', 'Large', 'Medium', 'Mini', 'Lower medium', 'Van', 'SUV']\n",
    "df_size_dist.plot.barh(stacked = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data on county level is available only for the rough motor division - aggregate the 7 \"PSI\" size classes into the motor size vehicles classes as used in HBEFA. The link between motor size and vehicle size is done based on some example cars (but can be discussed...): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_size_dist = df_size_dist.append(df_size_dist.loc[['Small', 'Mini']].sum(), \n",
    "                    ignore_index = True).drop([0,3])\n",
    "df_size_dist.index = ['Large', 'Medium', 'Lower medium', 'Van', 'SUV', 'Small']\n",
    "\n",
    "df_size_dist = df_size_dist.append(df_size_dist.loc[['Lower medium','Van', 'Medium']].sum(), ignore_index = True).drop([1,2,3])\n",
    "df_size_dist.index = ['Large', 'SUV', 'Small', 'Medium']\n",
    "\n",
    "df_size_dist = df_size_dist.append(df_size_dist.loc[['Large', 'SUV']].sum(), ignore_index = True).drop([0,1])\n",
    "df_size_dist.index = ['Small', 'Medium', 'Large']\n",
    "\n",
    "#Size distribution EV\n",
    "size_share_EV = df_size_dist/df_size_dist.sum()\n",
    "size_share_EV['Anzahl']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I only have data on the aggregated national level I need to adjust the size share of EVs in each county, as I know from the stock data that this will differ depending on the county. Compare the size distribution in each county to the average and adjust the EV share accordingly, this is done in size_share_EV. Then I multiply the shares with the total number of cars traded in in each county. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the sizes of electric vehicles we only have the national average, so compare the size distribution in each county to the national average\n",
    "df_size = pd.read_excel(\"./data/raw data/Replace and Retire/fz1_2019.xlsx\", sheet_name = 'Kfz_u_Kfz_Anh', skiprows = 8)\n",
    "\n",
    "df_rel_size_dist = pd.DataFrame(['Hubraum bis 1.399 cm続', '1.400 bis 1.999 cm続', '2.000 und mehr cm続'], [df_size.iloc[446][['Hubraum\\nbis \\n1.399 cm続', '1.400\\nbis\\n1.999 cm続','2.000\\nund\\nmehr cm続']].iloc[0], df_size.iloc[446][['Hubraum\\nbis \\n1.399 cm続', '1.400\\nbis\\n1.999 cm続','2.000\\nund\\nmehr cm続']].iloc[1], df_size.iloc[446][['Hubraum\\nbis \\n1.399 cm続', '1.400\\nbis\\n1.999 cm続','2.000\\nund\\nmehr cm続']].iloc[2]]).reset_index().set_index(0)\n",
    "df_rel_size_dist = (df_rel_size_dist/df_rel_size_dist.sum(axis = 0)).T\n",
    "df_rel_size_dist.index = ['average']\n",
    "df_rel_size_dist.columns = size_dist.columns\n",
    "\n",
    "#Want to see how the size distribution in each county compare to the national average in order to adjust the size distribution of the EV\n",
    "EV_adjust_size_dist = size_dist/df_rel_size_dist.values\n",
    "EV_adjust_size_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([size_share_EV.T]*59, ignore_index = True)\n",
    "df.index = EV_adjust_size_dist.index\n",
    "df.columns = EV_adjust_size_dist.columns\n",
    "size_share_EV = df*EV_adjust_size_dist\n",
    "\n",
    "size_share_EV.columns = ['Small', 'Medium', 'Large']\n",
    "\n",
    "#Need to normalize so the percentages sum to 1\n",
    "size_share_EV = (size_share_EV/[size_share_EV.sum(axis = 1),size_share_EV.sum(axis = 1),size_share_EV.sum(axis = 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_share_EV.index = index_list\n",
    "df_new = pd.concat([size_share_EV.loc[county]*sum(df_old.loc[county].sum()) for county in index_list], axis = 1).T\n",
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that this equals total number of cars (2 mill): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(df_new.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking that the total number of new cars equals the total number of old cars in each county \n",
    "assert(df_old.iloc[:,0:5].sum(axis =1).groupby('Statistische Kennziffer und Zulassungsbezirk').sum().values.round().any() ==df_new.sum(axis=1).values.round().any()), \"The number of new and old cars in each county is not equal\"\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting size and euro distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size and euro distribution in different counties for the old diesel cars: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_dist.index = index_list\n",
    "df_plot = pd.concat([size_dist.loc[index_list[0]],size_dist.loc[index_list[15]],size_dist.loc[index_list[20]]], axis = 1)*100\n",
    "df_plot.index = ['Small', 'Medium', 'Large']\n",
    "ax = df_plot.T.plot.barh(stacked = True, figsize = [6,4] )\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize = 10)\n",
    "ax.set_xlabel('Percentage', fontsize = 10)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tst = pd.DataFrame([df_old.loc[index_list[i]].sum(axis = 1)/sum(df_old.loc[index_list[i]].sum(axis = 1)) for i in np.arange(len(index_list))])\n",
    "tst.index = index_list\n",
    "tst.columns = ['Euro 1', 'Euro 2', 'Euro 3', 'Euro 4', 'Euro 5']\n",
    "df_plot=pd.concat([tst.loc[index_list[0]],tst.loc[index_list[15]],tst.loc[index_list[20]]], axis = 1)*100\n",
    "ax =df_plot.T.plot.barh(stacked = True, figsize = [5,3])\n",
    "ax.set_xlabel('Percentage')\n",
    "#plt.tight_layout()\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of vehicles exchanged are 2 million. \n",
    "The old are the diesel vehicles, new are the BEVs. See that we assume a downsizing effect, similar to the one observed in the 2009 program: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\")\n",
    "plt.figure(figsize=(1,1))\n",
    "df_old_plot = df_old.groupby('Statistische Kennziffer und Zulassungsbezirk').sum(axis = 1).sum()\n",
    "df_old_plot.index = ['Small', 'Medium', 'Large']\n",
    "ax = pd.concat([df_old_plot/1000000, df_new.sum()/1000000], keys= ['old', 'new']).unstack().plot.bar(stacked = True,rot = 0)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0)\n",
    "ax.set_ylabel('Million cars')\n",
    "\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eurodist_plot = df_old.sum(axis = 1).reset_index().groupby('level_1').sum()\n",
    "df_eurodist_plot.index = ['Euro 1', 'Euro 2', 'Euro 3', 'Euro 4', 'Euro 5']\n",
    "df_eurodist_plot.columns = ['']\n",
    "df_eurodist_plot.plot.pie(subplots = True, legend = None, figsize = [4,4], fontsize = 10)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
